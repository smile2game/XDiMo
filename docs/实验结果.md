# XDiMo 训练实验结果

模型: Latte-S/2 (75.14M 参数)，数据集: FFS 704 videos，配置见 `configs/ffs/`。

## 结果汇总表（4 卡对比）

| 硬件 | 模型参数 | 显存占用 | 硬件浮点峰值(FP16) | 样本吞吐(samples/s) | MFU | 加速比 |
|------|----------|----------|---------------------|---------------------|-----|--------|
| gpu_6000ada | 75.14M | ~18GB/卡 | 91.1 TFLOPs/卡 | 待测 | 待测 | 1.0 |
| gpu_h200 | 75.14M | ~18GB/卡 | 989 TFLOPs/卡 | 待测 | 待测 | 待测 |
| gpu_pro6000 | 75.14M | 待测 | 200 TFLOPs/卡 | 待测 | 待测 | 待测 |

*注：样本吞吐 = steps/s × global_batch；加速比以 6000ada 为基准 1.0。*

## 历史实验（修正后）

| 硬件 | GPU数 | global_batch | Steps/s | Achieved TFLOPs/s | MFU | 备注 |
|------|-------|--------------|---------|-------------------|-----|------|
| 6000ada | 8 | 8 | ~3.5 | ~235 | **~32%** | 修正峰值 91.1；原日志用错 26.9 导致 MFU 虚高 |
| H200 | 2 | 2 | ~5.1 | ~86 | ~4.3% | batch 过小，算力喂不饱 |

## MFU 优化方法

1. **增大 local_batch_size**：H200 80GB 可用 bs=4，6000ada/pro6000 48GB 可试 bs=2
2. **修正 GPU 峰值表**：`train.py` 中 `_GPU_PEAK_TFLOPS_FP16`，避免 MFU 虚高/虚低

## 脚本与配置

- 4 卡对比: `scripts/4gpu/{6000ada,h200,pro6000}/`，一键提交 `bash scripts/4gpu/submit_compare.sh`
- 若待提交任务数达上限，可单独提交: `jsub < scripts/4gpu/pro6000/baseline.sh`
- 配置: `configs/ffs/ffs_train_4gpu_bs{1,2,4}.yaml`
